# Lakehouse (pandas) â€“ EU Research Projects

> Medallion Architecture (Bronze/Silver/Gold) con **pandas + Parquet**, **Supabase (Postgres)** para consumo (Gold), **Typesense** para bÃºsqueda con filtros y **FastAPI** como API.
> DiseÃ±ado para sonar â€œDatabricks-readyâ€, pero simple de ejecutar localmente.

---

## ğŸ§­ Arquitectura

- **Data Lake local (filesystem)**

  - `lake/bronze/` â†’ archivos crudos (CSV, JSON, PDF opcional)
  - `lake/silver/` â†’ datos limpios/normalizados en **Parquet**
  - `lake/gold/` â†’ **esquema estrella** (dimensiones + hecho) en **Parquet**
- **ETL**: Python + **pandas**

  - `etl/bronze_to_silver.py`
  - `etl/silver_to_gold.py`
  - `etl/sync_to_supabase.py` â†’ carga Gold a **Supabase (Postgres)** con SQLAlchemy
- **API**: **FastAPI** (Basic Auth)

  - `/seed` â†’ corre ETL end-to-end
  - `/raw` â†’ CRUD mÃ­nimo de archivos en Bronze
  - `/gold/...` â†’ consultas a Supabase (dim/fact)
  - `/search` â†’ **Typesense** (texto + filtros)
- **Search**: **Typesense** (colecciÃ³n `projects_search`)

  - Campos: `project_id, title, abstract, country (facet), year (facet)`

> En Databricks: reemplazÃ¡s Parquet por **Delta Lake en DBFS/S3**, pandas por **PySpark** en notebooks, y Supabase por **SQL Warehouse**. Los endpoints API y Typesense se mantienen.

---

## ğŸ“ Estructura

```
.
â”œâ”€ api/
â”‚  â”œâ”€ main.py
â”‚  â”œâ”€ auth.py
â”‚  â”œâ”€ routes/
â”‚  â”‚  â”œâ”€ seed.py
â”‚  â”‚  â”œâ”€ raw.py
â”‚  â”‚  â”œâ”€ gold.py
â”‚  â”‚  â””â”€ search.py
â”‚  â”œâ”€ services/
â”‚  â”‚  â”œâ”€ db.py
â”‚  â”‚  â””â”€ typesense_client.py
â”‚  â””â”€ domain/
â”‚     â”œâ”€ raw_models.py
â”‚     â””â”€ gold_models.py
â”œâ”€ etl/
â”‚  â”œâ”€ bronze_to_silver.py
â”‚  â”œâ”€ silver_to_gold.py
â”‚  â””â”€ sync_to_supabase.py
â”œâ”€ data/
â”‚  â”œâ”€ bronze/   # CSV crudos (pegÃ¡ acÃ¡ tus archivos)
â”‚  â”œâ”€ silver/   # parquet limpios (salida ETL)
â”‚  â””â”€ gold/     # parquet star schema (salida ETL)
â”œâ”€ Dockerfile
â”œâ”€ docker-compose.yml
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## ğŸš€ Puesta en marcha

1) **Variables de entorno** â€“ crea `.env`:

```
BASIC_AUTH_USER=admin
BASIC_AUTH_PASS=supersecret

# Supabase / Postgres
SUPABASE_DB_URL=postgresql+psycopg://<user>:<pass>@<host>:6543/postgres?sslmode=require

# Typesense
TYPESENSE_API_KEY=xyz
TYPESENSE_HOST=typesense
TYPESENSE_PORT=8108
```

2) **Datos crudos**
   CopiÃ¡ los CSV a `data/bronze/` (ej.: `project.csv`, `organization.csv`, `topics.csv`, `policyPriorities.csv`, `legalBasis.csv`, `euroSciVoc.csv`, `webItem.csv`, `webLink.csv`).
3) **Levantar servicios**

```bash
docker compose up -d --build
```

4) **Seed end-to-end (ETL + carga a Supabase)**

```bash
curl -u admin:supersecret -X POST http://localhost:8000/seed
```

5) **Inicializar e indexar bÃºsqueda**

```bash
curl -u admin:supersecret -X POST http://localhost:8000/search/init
curl -u admin:supersecret -X POST http://localhost:8000/search/index
```

6) **Consultar Gold (Supabase)**

```bash
curl -u admin:supersecret "http://localhost:8000/gold/projects?country=DE&year=2022"
```

7) **Buscar (Typesense)**

```bash
curl -u admin:supersecret "http://localhost:8000/search?query=horizon&country=ES&year=2023"
```

8) **CRUD Raw**

```bash
# Crear/actualizar archivo en bronze
curl -u admin:supersecret -X POST http://localhost:8000/raw   -H "Content-Type: application/json"   -d '{"filename":"new_data/sample.csv","content":"col1,col2\nA,1\nB,2"}'

# Listar archivos
curl -u admin:supersecret "http://localhost:8000/raw/list"
```

---

## âœ… Requisitos de la Prueba (Checklist)

- [X] **Medallion Architecture** (Bronze/Silver/Gold)
- [X] **SQL DB accesible** (Supabase/Postgres)
- [X] **ORM/Modelado** con SQLAlchemy (carga vÃ­a `to_sql`)
- [X] **Esquema estrella** (â‰¥1 fact, â‰¥5 dims: `dim_project`, `dim_organization`, `dim_topic`, `dim_policy_priority`, `dim_legal_basis`, `dim_time` opcional)
- [X] **API FastAPI** (Basic Auth) con **CRUD batch/single** (raw), **/seed**, **/gold**, **/search**
- [X] **Vector DB**: Typesense en Docker (bÃºsqueda + filtro)
- [X] **Type hints / Pydantic** en dominio API
- [X] **Diagramas Mermaid** (ver abajo)

> Opcionales sugeridos (si querÃ©s sumar):
>
> - Calendar table (`dim_time`)
> - Materialized Views (en Supabase)
> - Lint + mypy + tests (pytest)
> - JWT + versionado de API (`/v1`, `/v2`)
> - Data lineage (logs, hashes, versionado de Parquet)

---

## ğŸ§­ Diagramas (Mermaid)

### 1) Lakehouse Global

```mermaid
flowchart LR
  subgraph Source["Source (CSV/JSON/PDF)"]
    A[project.csv]
    B[organization.csv]
    C[topics.csv]
    D[policyPriorities.csv]
    E[legalBasis.csv]
    F[euroSciVoc.csv]
    G[webItem.csv]
    H[webLink.csv]
  end

  A & B & C & D & E & F & G & H --> BR[Bronze (Filesystem)]
  BR -->|pandas ETL| SI[Silver (Parquet)]
  SI -->|modelado estrella| GO[Gold (Parquet)]

  GO -->|sync to_sql| DB[(Supabase / Postgres)]
  GO -->|index docs| VS[(Typesense)]

  subgraph API["FastAPI (Basic Auth)"]
    R1[/seed/]
    R2[/raw/]
    R3[/gold/.../]
    R4[/search/]
  end

  R1 --> BR
  R3 --> DB
  R4 --> VS
```

### 2) Bronze (Landing)

```mermaid
flowchart TB
  subgraph Bronze["Bronze (raw)"]
    P1[project.csv]
    P2[organization.csv]
    P3[topics.csv]
    P4[policyPriorities.csv]
    P5[legalBasis.csv]
    P6[euroSciVoc.csv]
    P7[webItem.csv]
    P8[webLink.csv]
  end
```

### 3) Silver (Conformed)

```mermaid
flowchart TB
  subgraph Silver["Silver (cleaned Parquet)"]
    S1[project.parquet\n- tipos normalizados\n- fechas tipadas\n- duration_days]
    S2[organization.parquet]
    S3[topics.parquet]
    S4[policyPriorities.parquet]
    S5[legalBasis.parquet]
    S6[euroSciVoc.parquet]
    S7[webItem.parquet]
    S8[webLink.parquet]
  end
```

### 4) Gold (Star Schema)

```mermaid
erDiagram
  DIM_PROJECT {
    bigint project_sk PK
    string project_id
    string title
    string abstract
    string program
    string country
    date   start_date
    date   end_date
    int    duration_days
    int    year
  }

  DIM_ORGANIZATION {
    bigint org_sk PK
    string org_id
    string org_name
    string org_type
    string org_country
  }

  DIM_TOPIC {
    bigint topic_sk PK
    string topic_code
    string topic_label
  }

  DIM_POLICY_PRIORITY {
    bigint priority_sk PK
    string code
    string label
  }

  DIM_LEGAL_BASIS {
    bigint legal_sk PK
    string code
    string label
  }

  FACT_PROJECT_FUNDING {
    bigint fact_id PK
    bigint project_sk FK
    bigint org_sk FK
    bigint topic_sk FK
    bigint priority_sk FK
    bigint legal_sk FK
    double funding_amount
    int    duration_days
    int    num_web_items
    int    num_links
  }

  DIM_PROJECT ||--o{ FACT_PROJECT_FUNDING : has
  DIM_ORGANIZATION ||--o{ FACT_PROJECT_FUNDING : has
  DIM_TOPIC ||--o{ FACT_PROJECT_FUNDING : has
  DIM_POLICY_PRIORITY ||--o{ FACT_PROJECT_FUNDING : has
  DIM_LEGAL_BASIS ||--o{ FACT_PROJECT_FUNDING : has
```

---

## ğŸ“œ Licencia

MIT (o la que prefieras).
