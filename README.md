# Lakehouse (pandas) â€“ EU Research Projects

> Arquitectura Lakehouse con **pandas + Parquet**, **Supabase (Postgres)** como DWH, **Typesense** para bÃºsqueda vectorial y **FastAPI** como API.
> OrquestaciÃ³n con **Airflow** (sensor de archivos y full pipeline).
> Incluye indexaciÃ³n de proyectos con embeddings (vectorizaciÃ³n) para bÃºsqueda semÃ¡ntica.

---

## ðŸ§­ Arquitectura General

- **Data Lake local (filesystem)**
  - `lake/bronze/` â†’ archivos crudos (CSV)
  - `lake/silver/` â†’ datos limpios/normalizados (Parquet)
  - `lake/gold/` â†’ modelo estrella (Parquet)
- **ETL modular (Python + pandas)**
  - Limpieza, normalizaciÃ³n, modelado y carga a Supabase/Postgres
  - IndexaciÃ³n en Typesense con embeddings (vectorizaciÃ³n)
- **OrquestaciÃ³n**
  - Airflow con dos DAGs:
    - `lakehouse_watch_any_file.py`: ejecuta ETL selectivo al detectar cambios en Bronze
    - `lakehouse_full_run.py`: ejecuta pipeline completo + vectorizaciÃ³n
- **API REST (FastAPI)**
  - Endpoints para consulta, bÃºsqueda, seed (disparar pipeline), CRUD de archivos
  - BÃºsqueda avanzada por texto y facetas usando Typesense

---

## ðŸ“‚ Estructura del Proyecto

```
.
â”œâ”€ api/                        # FastAPI: endpoints REST, autenticaciÃ³n, servicios
â”‚  â”œâ”€ main.py
â”‚  â”œâ”€ auth.py
â”‚  â”œâ”€ routes/
â”‚  â”‚  â”œâ”€ seed.py               # /seed â†’ dispara pipeline completo vÃ­a Airflow
â”‚  â”‚  â”œâ”€ raw.py                # /raw â†’ CRUD en Bronze
â”‚  â”‚  â”œâ”€ gold.py               # /gold â†’ queries sobre Gold/Supabase
â”‚  â”‚  â””â”€ search.py             # /search â†’ init, index, query en Typesense
â”‚  â”œâ”€ services/
â”‚  â”‚  â”œâ”€ db.py                 # ConexiÃ³n SQLAlchemy a Supabase/Postgres
â”‚  â”‚  â””â”€ typesense_client.py   # Cliente Typesense
â”‚  â””â”€ domain/                  # Modelos Pydantic
â”‚     â”œâ”€ raw_models.py
â”‚     â””â”€ gold_models.py
â”‚
â”œâ”€ etl/                        # Scripts ETL
â”‚  â”œâ”€ bronze_to_silver.py      # CSV â†’ Parquet (Silver)
â”‚  â”œâ”€ silver_to_gold.py        # Silver â†’ Gold (star schema)
â”‚  â”œâ”€ sync_to_supabase.py      # Gold â†’ Supabase (truncate & load)
â”‚  â””â”€ index_projects_typesense.py # Gold â†’ Typesense (vectorizaciÃ³n)
â”‚
â”œâ”€ orchestration/
â”‚  â””â”€ run_etl.py               # Funciones para ejecutar pipeline completo o selectivo
â”‚
â”œâ”€ dags/
â”‚  â”œâ”€ lakehouse_watch_any_file.py # DAG: sensor de cambios en Bronze + ETL selectivo + vectorizaciÃ³n
â”‚  â””â”€ lakehouse_full_run.py       # DAG: pipeline completo + vectorizaciÃ³n
â”‚
â”œâ”€ lake/
â”‚  â”œâ”€ bronze/                  # Archivos crudos
â”‚  â”œâ”€ silver/                  # Parquet normalizados
â”‚  â””â”€ gold/                    # Parquet star schema
â”‚
â”œâ”€ typesense-data/             # Persistencia de Typesense (volumen Docker)
â”œâ”€ airflow-logs/               # Logs de Airflow
â”œâ”€ Dockerfile
â”œâ”€ docker-compose.yml
â”œâ”€ requirements.txt
â”œâ”€ .env
â””â”€ README.md
```

---

## ðŸš€ Puesta en marcha

1. **Prepara carpetas persistentes:**

   ```bash
   mkdir -p lake/bronze lake/silver lake/gold typesense-data dags airflow-logs
   ```
2. **Coloca los archivos CSV en `lake/bronze/`**Ejemplo: `project.csv`, `organization.csv`, `topics.csv`, etc.
3. **Configura variables en `.env`**Incluye credenciales de Supabase/Postgres y Typesense.

   Ejemplo de `.env`:

   ```
   SUPABASE_DB_URL=postgresql://user:password@host:5432/dbname
   TYPESENSE_API_KEY=your_typesense_api_key
   AIRFLOW_API_URL=http://localhost:8080/api/v1
   AIRFLOW_API_TOKEN=your_airflow_token
   ```
4. **Levanta los servicios:**

   ```bash
   docker compose up --build
   ```
5. **Accede a los servicios:**

   - **API:** [http://localhost:8000/docs](http://localhost:8000/docs)
   - **Airflow:** [http://localhost:8080](http://localhost:8080)
   - **Typesense:** [http://localhost:8108](http://localhost:8108)

---

## ðŸ› ï¸ ETL y VectorizaciÃ³n

- **bronze_to_silver.py:**Limpia y normaliza los datos crudos de Bronze a Silver (Parquet).
- **silver_to_gold.py:**Modela los datos Silver en un esquema estrella Gold (Parquet).
- **sync_to_supabase.py:**Carga las tablas Gold en Supabase/Postgres para consultas SQL y API.
- **index_projects_typesense.py:**
  Lee proyectos Gold, genera embeddings con un modelo transformer y los indexa en Typesense para bÃºsqueda semÃ¡ntica y facetada.

---

## âš¡ OrquestaciÃ³n (Airflow)

- **lakehouse_watch_any_file.py:**

  - Sensor detecta cambios en archivos Bronze.
  - Ejecuta ETL solo para los archivos modificados.
  - Vectoriza e indexa proyectos nuevos en Typesense.
- **lakehouse_full_run.py:**

  - Ejecuta el pipeline completo (Bronze â†’ Silver â†’ Gold â†’ Supabase).
  - Vectoriza e indexa todos los proyectos en Typesense.

---

## ðŸŒ API REST (FastAPI)

### Endpoints principales

- **`/seed`**`POST /seed`Dispara el DAG `lakehouse_full_run` vÃ­a Airflow para ejecutar el pipeline completo y vectorizaciÃ³n.
- **`/raw`**CRUD de archivos en Bronze (subida, listado, borrado).
- **`/gold/projects`**Consulta proyectos en Gold/Supabase, filtrando por paÃ­s y aÃ±o.
- **`/search`**

  - `POST /search/init` : Inicializa la colecciÃ³n en Typesense.
  - `POST /search/index`: Indexa proyectos Gold en Typesense (incluye embeddings).
  - `GET /search`       : BÃºsqueda por texto y filtros (paÃ­s, aÃ±o, facetas).

### Ejemplo de uso

```bash
# Disparar pipeline completo
curl -u admin:supersecret -X POST http://localhost:8000/seed

# Inicializar colecciÃ³n de bÃºsqueda
curl -u admin:supersecret -X POST http://localhost:8000/search/init

# Indexar proyectos en Typesense
curl -u admin:supersecret -X POST http://localhost:8000/search/index

# Buscar proyectos
curl -u admin:supersecret "http://localhost:8000/search?q=ai&country=DE&year=2023"
```

---

## ðŸ§© ConfiguraciÃ³n avanzada

- **Persistencia de Typesense:**Usa solo la carpeta `typesense-data` como volumen Docker.Si necesitas limpiar el Ã­ndice, puedes borrar la carpeta y reiniciar el servicio.
- **Variables de entorno:**Ajusta `.env` para tus credenciales y rutas.Puedes cambiar el puerto de la API, la URL de Airflow, etc.
- **Embeddings:**El script `index_projects_typesense.py` usa un modelo transformer (ej. `sentence-transformers`) para generar vectores.Puedes cambiar el modelo en el script segÃºn tus necesidades.
- **Airflow:**
  La API `/seed` dispara el DAG `lakehouse_full_run` usando la API REST de Airflow.
  AsegÃºrate de que Airflow tenga la API habilitada y el DAG estÃ© en la carpeta `dags/`.

---

## âœ… Checklist de la SoluciÃ³n

- [X] Arquitectura Medallion (Bronze/Silver/Gold)
- [X] ETL modular y reproducible
- [X] Data warehouse relacional (Supabase/Postgres)
- [X] Modelo estrella en Gold
- [X] API REST con autenticaciÃ³n bÃ¡sica
- [X] BÃºsqueda vectorial y facetada en Typesense
- [X] OrquestaciÃ³n con Airflow (sensor + full pipeline)
- [X] IndexaciÃ³n con embeddings (transformer)
- [X] Docker Compose para levantar todo el stack

---

## ðŸ’¬ Notas finales

- El pipeline y la arquitectura son fÃ¡cilmente migrables a entornos cloud (Databricks, Delta Lake, etc.).
- Puedes ampliar la bÃºsqueda vectorial, agregar facetas o sumar endpoints segÃºn tus necesidades.
- La persistencia de Typesense debe estar en la carpeta `typesense-data` (ver `docker-compose.yml`).

---


## ðŸ§­ Diagramas (Mermaid)

### 1) Lakehouse Global

```mermaid
flowchart LR
  subgraph Source["Source (CSV/JSON/PDF)"]
    A[project.csv]
    B[organization.csv]
    C[topics.csv]
    D[policyPriorities.csv]
    E[legalBasis.csv]
    F[euroSciVoc.csv]
    G[webItem.csv]
    H[webLink.csv]
  end

  A & B & C & D & E & F & G & H --> BR[Bronze (Filesystem)]
  BR -->|pandas ETL| SI[Silver (Parquet)]
  SI -->|modelado estrella| GO[Gold (Parquet)]

  GO -->|sync to_sql| DB[(Supabase / Postgres)]
  GO -->|index docs| VS[(Typesense)]

  subgraph API["FastAPI (Basic Auth)"]
    R1[/seed/]
    R2[/raw/]
    R3[/gold/.../]
    R4[/search/]
  end

  R1 --> BR
  R3 --> DB
  R4 --> VS
```

### 2) Bronze (Landing)

```mermaid
flowchart TB
  subgraph Bronze["Bronze (raw)"]
    P1[project.csv]
    P2[organization.csv]
    P3[topics.csv]
    P4[policyPriorities.csv]
    P5[legalBasis.csv]
    P6[euroSciVoc.csv]
    P7[webItem.csv]
    P8[webLink.csv]
  end
```

### 3) Silver (Conformed)

```mermaid
flowchart TB
  subgraph Silver["Silver (cleaned Parquet)"]
    S1[project.parquet\n- tipos normalizados\n- fechas tipadas\n- duration_days]
    S2[organization.parquet]
    S3[topics.parquet]
    S4[policyPriorities.parquet]
    S5[legalBasis.parquet]
    S6[euroSciVoc.parquet]
    S7[webItem.parquet]
    S8[webLink.parquet]
  end
```

### 4) Gold (Star Schema)

```mermaid
erDiagram
  DIM_PROJECT {
    bigint project_sk PK
    string project_id
    string title
    string abstract
    string program
    string country
    date   start_date
    date   end_date
    int    duration_days
    int    year
  }

  DIM_ORGANIZATION {
    bigint org_sk PK
    string org_id
    string org_name
    string org_type
    string org_country
  }

  DIM_TOPIC {
    bigint topic_sk PK
    string topic_code
    string topic_label
  }

  DIM_POLICY_PRIORITY {
    bigint priority_sk PK
    string code
    string label
  }

  DIM_LEGAL_BASIS {
    bigint legal_sk PK
    string code
    string label
  }

  FACT_PROJECT_FUNDING {
    bigint fact_id PK
    bigint project_sk FK
    bigint org_sk FK
    bigint topic_sk FK
    bigint priority_sk FK
    bigint legal_sk FK
    double funding_amount
    int    duration_days
    int    num_web_items
    int    num_links
  }

  DIM_PROJECT ||--o{ FACT_PROJECT_FUNDING : has
  DIM_ORGANIZATION ||--o{ FACT_PROJECT_FUNDING : has
  DIM_TOPIC ||--o{ FACT_PROJECT_FUNDING : has
  DIM_POLICY_PRIORITY ||--o{ FACT_PROJECT_FUNDING : has
  DIM_LEGAL_BASIS ||--o{ FACT_PROJECT_FUNDING : has
```

---

## ðŸ“œ Licencia

MIT (o la que prefieras).
