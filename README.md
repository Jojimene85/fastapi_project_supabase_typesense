
# Lakehouse (pandas) ‚Äì EU Research Projects

> Arquitectura Lakehouse con **pandas + Parquet**, **Supabase (Postgres)** como DWH, **Typesense** para b√∫squeda vectorial y **FastAPI** como API.
> Orquestaci√≥n con **Airflow** (sensores de archivos y pipeline completo).
> Incluye indexaci√≥n de proyectos con embeddings (vectorizaci√≥n) generados mediante una funci√≥n en Supabase para b√∫squeda sem√°ntica.
> Testing automatizado para aseguramiento de calidad.

---

## üß≠ Arquitectura General

- **Data Lake local (filesystem)**
  - `lake/bronze/` ‚Üí archivos crudos (CSV)
  - `lake/silver/` ‚Üí datos limpios/normalizados (Parquet)
  - `lake/gold/` ‚Üí modelo estrella (Parquet)
- **ETL modular (Python + pandas)**
  - Limpieza, normalizaci√≥n, modelado y carga en Supabase/Postgres
  - Indexaci√≥n en Typesense con embeddings (vectorizaci√≥n)
- **Orquestaci√≥n**
  - Airflow con dos DAGs:
    - `lakehouse_watch_any_file.py`: ejecuta ETL selectivo al detectar cambios en Bronze
    - `lakehouse_full_run.py`: ejecuta el pipeline completo + vectorizaci√≥n
- **API REST (FastAPI)**
  - Endpoints para consulta, b√∫squeda, disparo del pipeline (seed) y CRUD de archivos
  - B√∫squeda avanzada por texto y facetas usando Typesense
- **Testing**
  - Tests autom√°ticos para verificar la correcta operaci√≥n de los ETL, endpoints y b√∫squeda.

---

## üõ†Ô∏è Tecnolog√≠as utilizadas

- **Python 3.10+** ‚Äì Lenguaje principal de programaci√≥n
- **Pandas** ‚Äì Manipulaci√≥n de datos y ETL
- **FastAPI** ‚Äì Framework para APIs RESTful
- **Supabase (Postgres)** ‚Äì Base de datos en la nube y hosting
- **Typesense** ‚Äì Motor de b√∫squeda vectorial y facetada
- **Docker & Docker Compose** ‚Äì Contenerizaci√≥n y orquestaci√≥n
- **Apache Airflow** ‚Äì Orquestaci√≥n de flujos de trabajo (DAGs, sensores)
- **Pytest** ‚Äì Testing automatizado
- **SQLAlchemy** ‚Äì ORM e interacci√≥n con la base de datos
- **Parquet** ‚Äì Formato de almacenamiento columnar para Silver/Gold
- **Mermaid** ‚Äì Diagramas de arquitectura en markdown

---

## üß© Estructura del Proyecto

```
.
‚îú‚îÄ api/                        # FastAPI: endpoints REST, autenticaci√≥n, servicios
‚îÇ  ‚îú‚îÄ main.py
‚îÇ  ‚îú‚îÄ auth.py
‚îÇ  ‚îú‚îÄ routes/
‚îÇ  ‚îÇ  ‚îú‚îÄ seed.py               # /seed ‚Üí dispara pipeline completo v√≠a Airflow
‚îÇ  ‚îÇ  ‚îú‚îÄ raw.py                # /raw ‚Üí CRUD en Bronze
‚îÇ  ‚îÇ  ‚îú‚îÄ gold.py               # /gold ‚Üí queries en Gold/Supabase
‚îÇ  ‚îÇ  ‚îî‚îÄ search.py             # /search ‚Üí init, index, query en Typesense
‚îÇ  ‚îú‚îÄ services/
‚îÇ  ‚îÇ  ‚îú‚îÄ db.py                 # Conexi√≥n SQLAlchemy a Supabase/Postgres
‚îÇ  ‚îÇ  ‚îú‚îÄ typesense_client.py   # Cliente Typesense
‚îÇ  ‚îÇ  ‚îî‚îÄ embeddings.py         # L√≥gica de embeddings (integraci√≥n funci√≥n Supabase)
‚îÇ  ‚îî‚îÄ domain/                  # Modelos Pydantic
‚îÇ     ‚îú‚îÄ raw_models.py
‚îÇ     ‚îî‚îÄ gold_models.py
‚îÇ
‚îú‚îÄ etl/                        # Scripts ETL
‚îÇ  ‚îú‚îÄ bronze_to_silver.py      # CSV ‚Üí Parquet (Silver)
‚îÇ  ‚îú‚îÄ silver_to_gold.py        # Silver ‚Üí Gold (star schema)
‚îÇ  ‚îú‚îÄ sync_to_supabase.py      # Gold ‚Üí Supabase (truncate & load)
‚îÇ  ‚îî‚îÄ index_projects_typesense.py # Gold ‚Üí Typesense (vectorizaci√≥n)
‚îÇ
‚îú‚îÄ orchestration/
‚îÇ  ‚îî‚îÄ run_etl.py               # Funciones para ejecutar pipeline completo o selectivo
‚îÇ
‚îú‚îÄ dags/
‚îÇ  ‚îú‚îÄ lakehouse_watch_any_file.py # DAG: sensor de cambios en Bronze + ETL selectivo + vectorizaci√≥n
‚îÇ  ‚îî‚îÄ lakehouse_full_run.py       # DAG: pipeline completo + vectorizaci√≥n
‚îÇ
‚îú‚îÄ lake/
‚îÇ  ‚îú‚îÄ bronze/                  # Archivos crudos
‚îÇ  ‚îú‚îÄ silver/                  # Parquet normalizados
‚îÇ  ‚îî‚îÄ gold/                    # Parquet star schema
‚îÇ
‚îú‚îÄ typesense-data/             # Persistencia de Typesense (volumen Docker)
‚îú‚îÄ airflow-logs/               # Logs de Airflow
‚îú‚îÄ tests/                      # Tests autom√°ticos (Pytest)
‚îú‚îÄ Dockerfile
‚îú‚îÄ docker-compose.yml
‚îú‚îÄ requirements.txt
‚îú‚îÄ .env
‚îî‚îÄ README.md
```

---

## üöÄ Puesta en marcha

**Toda la operaci√≥n se realiza levantando el stack con Docker Compose.**

### 1. Prepara carpetas persistentes

```bash
mkdir -p lake/bronze lake/silver lake/gold typesense-data dags airflow-logs
```

### 2. Coloca los archivos CSV en `lake/bronze/`

Ejemplo: `project.csv`, `organization.csv`, `topics.csv`, etc.

### 3. Configura variables en `.env`

Incluye credenciales de Supabase/Postgres, Typesense y Airflow.

Ejemplo de `.env`:

```
SUPABASE_DB_URL=postgresql://user:password@host:5432/dbname
TYPESENSE_API_KEY=your_typesense_api_key
AIRFLOW_API_URL=http://localhost:8080/api/v1
AIRFLOW_API_TOKEN=your_airflow_token
```

### 4. Levanta el stack completo

```bash
docker compose up --build
```

Esto inicia todos los servicios: API, Airflow, Typesense, base de datos, etc.
Puedes operar ETL, b√∫squedas, testing, todo desde los servicios Docker.

### 5. Accede a los servicios

- **API:** [http://localhost:8000/docs](http://localhost:8000/docs)
- **Airflow:** [http://localhost:8080](http://localhost:8080)
- **Typesense:** [http://localhost:8108](http://localhost:8108)

### 6. Ejecuta los tests

```bash
docker compose exec api pytest tests/
```

---

## üõ†Ô∏è ETL, Embeddings y Vectorizaci√≥n

- **bronze_to_silver.py:** Limpia y normaliza los datos crudos de Bronze a Silver (Parquet).
- **silver_to_gold.py:** Modela los datos Silver en un esquema estrella Gold (Parquet).
- **sync_to_supabase.py:** Carga las tablas Gold en Supabase/Postgres para consultas SQL y API.
- **Embeddings en Supabase:**Los embeddings se generan usando una funci√≥n definida en Supabase, directamente sobre los registros Gold. La l√≥gica est√° implementada en `api/services/embeddings.py`.
- **index_projects_typesense.py:**
  Lee los embeddings y proyectos Gold desde Supabase y los indexa en Typesense para b√∫squeda sem√°ntica y facetada.

---

## ‚ö° Orquestaci√≥n (Airflow)

- **lakehouse_watch_any_file.py:**
  - Sensor detecta cambios en archivos Bronze.
  - Ejecuta ETL solo para los archivos modificados.
  - Vectoriza e indexa proyectos nuevos en Typesense.
- **lakehouse_full_run.py:**
  - Ejecuta el pipeline completo (Bronze ‚Üí Silver ‚Üí Gold ‚Üí Supabase).
  - Genera embeddings en Supabase y los indexa en Typesense.

---

## üåê API REST (FastAPI)

### Endpoints principales

- **`/seed`**`POST /seed` Dispara el DAG `lakehouse_full_run` v√≠a Airflow para ejecutar el pipeline completo y vectorizaci√≥n.
- **`/raw`**CRUD de archivos en Bronze (subida, listado, borrado).
- **`/gold/projects`**Consulta proyectos en Gold/Supabase, filtrando por pa√≠s y a√±o.
- **`/search`**
  - `POST /search/init` : Inicializa la colecci√≥n en Typesense.
  - `POST /search/index`: Indexa proyectos Gold en Typesense (incluye embeddings desde Supabase).
  - `GET /search`       : B√∫squeda por texto y filtros (pa√≠s, a√±o, facetas).

### Ejemplo de uso

```bash
# Disparar pipeline completo
curl -u admin:supersecret -X POST http://localhost:8000/seed

# Inicializar colecci√≥n de b√∫squeda
curl -u admin:supersecret -X POST http://localhost:8000/search/init

# Indexar proyectos en Typesense
curl -u admin:supersecret -X POST http://localhost:8000/search/index

# Buscar proyectos
curl -u admin:supersecret "http://localhost:8000/search?q=ai&country=DE&year=2023"
```

---

## üß™ Testing

- **Cobertura:**Los tests cubren los siguientes aspectos:
  - Funcionamiento de los ETL.
  - Validaci√≥n de endpoints de la API.
  - Integridad y precisi√≥n de b√∫squedas en Typesense.
- **Herramienta:**
  Se utiliza `pytest` y pueden ejecutarse con:
  ```bash
  docker compose exec api pytest tests/
  ```

---

## ‚úÖ Checklist de la Soluci√≥n

- [X] Arquitectura Medallion (Bronze/Silver/Gold)
- [X] ETL modular y reproducible
- [X] Data warehouse relacional (Supabase/Postgres)
- [X] Modelo estrella en Gold
- [X] API REST con autenticaci√≥n b√°sica
- [X] B√∫squeda vectorial y facetada en Typesense
- [X] Orquestaci√≥n con Airflow (sensor + pipeline completo)
- [X] Indexaci√≥n con embeddings (funci√≥n en Supabase, ver `embeddings.py`)
- [X] M√≥dulo de testing automatizado
- [X] Docker Compose para levantar todo el stack

---

## üí¨ Notas finales

- El pipeline y la arquitectura son f√°cilmente migrables a entornos cloud (Databricks, Delta Lake, etc.).
- Puedes ampliar la b√∫squeda vectorial, agregar facetas o sumar endpoints seg√∫n tus necesidades.
- La persistencia de Typesense debe estar en la carpeta `typesense-data` (ver `docker-compose.yml`).

---

## üß≠ Diagramas (Mermaid)

### 1) Lakehouse Global

```mermaid
flowchart LR
  subgraph Source["Source (CSV/JSON/PDF)"]
    A[project.csv]
    B[organization.csv]
    C[topics.csv]
    D[policyPriorities.csv]
    E[legalBasis.csv]
    F[euroSciVoc.csv]
    G[webItem.csv]
    H[webLink.csv]
  end

  A & B & C & D & E & F & G & H --> BR[Bronze (Filesystem)]
  BR -->|pandas ETL| SI[Silver (Parquet)]
  SI -->|modelado estrella| GO[Gold (Parquet)]

  GO -->|carga y embeddings (funci√≥n en Supabase)| DB[(Supabase / Postgres)]
  DB -->|index docs| VS[(Typesense)]

  subgraph API["FastAPI (Basic Auth)"]
    R1[/seed/]
    R2[/raw/]
    R3[/gold/.../]
    R4[/search/]
  end

  R1 --> BR
  R3 --> DB
  R4 --> VS
```

### 2) Bronze (Landing)

```mermaid
flowchart TB
  subgraph Bronze["Bronze (raw)"]
    P1[project.csv]
    P2[organization.csv]
    P3[topics.csv]
    P4[policyPriorities.csv]
    P5[legalBasis.csv]
    P6[euroSciVoc.csv]
    P7[webItem.csv]
    P8[webLink.csv]
  end
```

### 3) Silver (Conformed)

```mermaid
flowchart TB
  subgraph Silver["Silver (cleaned Parquet)"]
    S1[project.parquet\n- tipos normalizados\n- fechas tipadas\n- duration_days]
    S2[organization.parquet]
    S3[topics.parquet]
    S4[policyPriorities.parquet]
    S5[legalBasis.parquet]
    S6[euroSciVoc.parquet]
    S7[webItem.parquet]
    S8[webLink.parquet]
  end
```

### 4) Gold (Star Schema)

```mermaid
erDiagram
  DIM_PROJECT {
    bigint project_sk PK
    string project_id
    string title
    string abstract
    string program
    string country
    date   start_date
    date   end_date
    int    duration_days
    int    year
  }

  DIM_ORGANIZATION {
    bigint org_sk PK
    string org_id
    string org_name
    string org_type
    string org_country
  }

  DIM_TOPIC {
    bigint topic_sk PK
    string topic_code
    string topic_label
  }

  DIM_POLICY_PRIORITY {
    bigint priority_sk PK
    string code
    string label
  }

  DIM_LEGAL_BASIS {
    bigint legal_sk PK
    string code
    string label
  }

  FACT_PROJECT_FUNDING {
    bigint fact_id PK
    bigint project_sk FK
    bigint org_sk FK
    bigint topic_sk FK
    bigint priority_sk FK
    bigint legal_sk FK
    double funding_amount
    int    duration_days
    int    num_web_items
    int    num_links
  }

  DIM_PROJECT ||--o{ FACT_PROJECT_FUNDING : has
  DIM_ORGANIZATION ||--o{ FACT_PROJECT_FUNDING : has
  DIM_TOPIC ||--o{ FACT_PROJECT_FUNDING : has
  DIM_POLICY_PRIORITY ||--o{ FACT_PROJECT_FUNDING : has
  DIM_LEGAL_BASIS ||--o{ FACT_PROJECT_FUNDING : has
```

---

## ü§ù Contribuci√≥n

¬°Las contribuciones son bienvenidas!
Por favor, abre un issue o un pull request para sugerencias, mejoras o correcciones.
Para reportar bugs, utiliza el m√≥dulo de testing y adjunta resultados.

---

## üìú Licencia

MIT

<style>#mermaid-1757921586946{font-family:sans-serif;font-size:16px;fill:#333;}#mermaid-1757921586946 .error-icon{fill:#552222;}#mermaid-1757921586946 .error-text{fill:#552222;stroke:#552222;}#mermaid-1757921586946 .edge-thickness-normal{stroke-width:2px;}#mermaid-1757921586946 .edge-thickness-thick{stroke-width:3.5px;}#mermaid-1757921586946 .edge-pattern-solid{stroke-dasharray:0;}#mermaid-1757921586946 .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-1757921586946 .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-1757921586946 .marker{fill:#333333;}#mermaid-1757921586946 .marker.cross{stroke:#333333;}#mermaid-1757921586946 svg{font-family:sans-serif;font-size:16px;}#mermaid-1757921586946 .label{font-family:sans-serif;color:#333;}#mermaid-1757921586946 .label text{fill:#333;}#mermaid-1757921586946 .node rect,#mermaid-1757921586946 .node circle,#mermaid-1757921586946 .node ellipse,#mermaid-1757921586946 .node polygon,#mermaid-1757921586946 .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-1757921586946 .node .label{text-align:center;}#mermaid-1757921586946 .node.clickable{cursor:pointer;}#mermaid-1757921586946 .arrowheadPath{fill:#333333;}#mermaid-1757921586946 .edgePath .path{stroke:#333333;stroke-width:1.5px;}#mermaid-1757921586946 .flowchart-link{stroke:#333333;fill:none;}#mermaid-1757921586946 .edgeLabel{background-color:#e8e8e8;text-align:center;}#mermaid-1757921586946 .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#mermaid-1757921586946 .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-1757921586946 .cluster text{fill:#333;}#mermaid-1757921586946 div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:sans-serif;font-size:12px;background:hsl(80,100%,96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-1757921586946:root{--mermaid-font-family:sans-serif;}#mermaid-1757921586946:root{--mermaid-alt-font-family:sans-serif;}#mermaid-1757921586946 flowchart-v2{fill:apa;}</style>
